# ch.03 회귀 알고리즘과 모델 규제 - 농어 무게 예측
## 03-1 k-최근접 이웃 회귀
지도 학습 종류
- 분류: 샘플을 몇 개의 클래스 중 하나로 분류하는 문제
- 회귀: 임의의 어떤 숫자를 예측하는 문제  
예> 내년도 경제 성장률 예측, 배달이 도착할 시간 예측, 농어의 무게 예측
---
k-최근접 이웃 알고리즘을 회귀에 적용해보자!
- knn 알고리즘
1. 예측하려는 샘플에 가장 가까운 샘플 k개 선택
2. 해당 샘플들의 클래스 확인
3. 다수 클래스를 새로운 샘플의 클래스로 예측
![title](https://miro.medium.com/max/506/0*QyWp7J6eSz0tayc0.png)   
위 그림의 경우 new sample을 빨간 별로 예측할 것이다. 
- 그럼 knn 회귀는?  
분류와 똑같이 예측하려는 샘플에 가장 가까운 샘플 k개를 선택 후 평균을 구한다.
(이전 분류 문제의 경우 k값을 홀수로만 설정할 수 있었는데 평균을 내는 지금은 홀수든 짝수든 상관 없을 듯?)
![title](https://velog.velcdn.com/images/coffeebaraa/post/03bc12b2-3f43-4530-866a-d27230547f09/image.jpeg)   
---
### 농어 길이로 무게 예측하기!
[google colab 실습 코드](https://colab.research.google.com/drive/1u54xCxFVzdboyD_qviEGMQ_93BNIq43p?usp=sharing)   
- 결정계수(R^2)  
분류에서는 테스트 데이터에 있는 샘플을 정확하게 분류한 개수의 비율 즉, 정확도로 평가했음.  

하지만 회귀에서는 결정계수로 평가한다.  
결정계수가 1에 가까울 수록 해당 데이터 셋에 대해 모델이 잘 예측한다는 의미이고, 반면 0에 가까울 수록 단순히 평균값으로 예측한 경우와 유사하다는 뜻이고 0보다 낮을 경우 평균으로 예측한 것보다 더 못했다는 의미이다.


현재 score를 확인해보았을 때 train data set 보다 test data set이 더 높게 나옴!  
원래는 train data set이 더 높게 나오는게 일반적임. 약간 기출 그대로 시험에 나온 느낌이니까!  
만약 train data set에서는 점수가 굉장히 좋았는데 test data set에서는 굉장히 안 좋다! 이럴 때는 모델이 과적합 되어서 train data set에만 맞고 다른 데이터에는 오히려 맞지 않는 것이다.
![title](https://blog.kakaocdn.net/dn/ckfx8t/btrnqysT3uR/P3KJqiBxLn6Of3st4gH4N1/img.jpg)   
반대로 test data set에서의 점수가 더 높다면 아직 학습이 잘 안 됐다고 보는 것이다. 
과소적합의 원인은 크게 두가지이다. 모델이 너무 단순하거나 학습 데이터가 너무 작거나!  
그럼 knn에서 모델을 더 복잡하게 만든다는 것은 어떤 의미일까? 
바로 k의 개수를 줄이는 것이다. 그럼 더욱 인접한 데이터들만 최종 결정에 사용되기 때문에 훈련 data set에 더 적합한 모델이 나오게 될 것이다. 반면에 k 개수를 늘리면 결정할 때 참고하는 data가 늘어나기 때문에 더 포괄적인 모델이 나올 것이다. 

---
정리해보면 일반적으로 훈련 데이터 셋에 대한 score가 더 높은 것이 당연한 것이지만, 테스트 데이터 셋과 너무 차이가 나면 과적합 됐다는 의미이다.
반면에, 테스트 데이터 셋 스코어가 더 높으면 과소적합되었다는 의미이다.  
과대적합인 경우에는 k의 수를 늘려야하고,
과소적합인 경우에는 줄여야한다. 
