# K-최근접 이웃 회귀 (K-Nearest Neighbors Regression)

### 개념

- 예측하려는 샘플에 가장 가까운 샘플 **k개**를 선택.
- **분류 문제**: 선택된 샘플들의 클래스를 확인하여 다수의 클래스를 새로운 클래스로 예측.
- **회귀 문제**: 선택된 샘플들의 값을 평균 내어 예측값으로 사용.

---

# 결정 계수 (R²)

### 정의

- 회귀 모델에서 모델 성능을 평가하는 지표.
- **수식**  
  \[
  R^2 = 1 - \frac{\sum(target - pred)^2}{\sum(target - mean)^2}
  \]

### 계산 과정

1. 각 샘플의 타깃 값과 예측값의 차이를 제곱하여 더함.
2. 타깃 값과 타깃 평균의 차이를 제곱하여 더한 값으로 나눔.

### 특징

- **R² 값의 범위**: 0 ≤ R² ≤ 1
  - R²이 **1**에 가까울수록 모델이 타깃 값을 잘 예측.
  - R²이 **0**에 가까우면, 모델이 타깃의 평균 수준으로만 예측.

---

# 과대적합 vs 과소적합

### 과대적합 (Overfitting)

- **특징**: 훈련 세트에서 점수가 매우 높지만, 테스트 세트 점수는 낮음.
- **문제점**: 모델이 훈련 데이터에 너무 맞춰져 새로운 데이터에 일반화하지 못함.

### 과소적합 (Underfitting)

- **특징**: 훈련 세트와 테스트 세트 점수가 모두 낮거나, 테스트 세트 점수가 훈련 세트보다 높음.
- **문제점**: 모델이 데이터의 패턴을 충분히 학습하지 못함.

### K-최근접 이웃의 한계

- **제한점**: 새로운 샘플이 훈련 세트의 범위를 벗어나면 엉뚱한 값을 예측하게 됨.

---

### 선형 회귀 (Linear Regression)

- **개념**: 특성이 하나인 경우, 데이터를 가장 잘 설명하는 직선을 학습하는 알고리즘.

---

### 다항 회귀 (Polynomial Regression)

- **개념**: 데이터를 다항식(polynomial)으로 표현하여 학습하는 선형 회귀.

---

### 다중 회귀 (Multiple Regression)

- **개념**: 여러 개의 특성을 사용하여 학습하는 선형 회귀.

---

### 특성공학 (Feature Engineering)

- **정의**: 기존 특성을 활용하여 새로운 특성을 생성하는 과정.
- 모델 성능을 향상시키기 위해 데이터에서 더 유용한 정보를 추출.

---

### 변환기 (Transformer)

- **정의**: 특성을 생성하거나 전처리하기 위한 클래스.
- **사이킷런에서의 사용**: `transformer`를 활용하여 특성 변환 및 전처리를 수행.


Multiple
linear regression blue