# 3-1 K-최근접 이웃 회귀

## **1. 회귀**

- **회귀**는 연속적인 값을 예측하는 머신러닝 모델의 한 종류.
- 입력 데이터(features)와 타깃 값(target) 사이의 관계를 학습하여 예측을 수행.
- 예: 주택 가격 예측, 온도 예측 등.

---

## **2. 결정계수 \( R^2 \)**

- **결정계수 \( R^2 \)**는 회귀 모델의 성능을 평가하는 지표로, **모델이 타깃 변수를 얼마나 잘 설명하는지**를 나타냄.
- **공식**:
  \[
  R^2 = 1 - \frac{\sum (y - \hat{y})^2}{\sum (y - \bar{y})^2}
  \]
  - \( y \): 실제 값(타깃 값).
  - \( \hat{y} \): 모델의 예측 값.
  - \( \bar{y} \): 타깃 값의 평균.

### **2.1 +, - 값의 영향**

- \( R^2 \) 계산에서는 \( (y - \hat{y})^2 \)와 \( (y - \bar{y})^2 \)처럼 **제곱 값**을 사용하기 때문에, + 또는 - 부호의 영향은 무시됨.
- 오직 **오차 크기**만이 영향을 미침.

### **2.2 결정계수가 높으면?**

- 모델이 타깃 변수를 잘 설명한다는 의미.
- 모델의 예측 값이 실제 값과 매우 가까움을 나타냄.

### **2.3 결정계수가 낮으면?**

- 모델이 타깃 변수를 제대로 설명하지 못함.
- 예측 값이 실제 값과 차이가 크거나, 데이터의 패턴을 제대로 학습하지 못했음을 의미.

### **2.4 \( R^2 = 0.99 \)는 좋은 값?**

- \( R^2 = 0.99 \)는 매우 높은 값으로, 일반적으로 모델이 데이터를 잘 설명한다고 볼 수 있음.
- 하지만 **결정계수는 상대적인 기준**:
  - 데이터의 복잡성, 크기, 과적합 여부 등을 함께 고려해야 함.
  - 지나치게 높은 \( R^2 \)는 과적합 가능성을 의심해야 함.

---

## **3. K-최근접 이웃 회귀 모델 (KNN Regression)**

- **K-최근접 이웃 회귀**는 특정 데이터 포인트의 예측 값을 **주변 K개의 이웃 값의 평균**으로 계산하는 알고리즘.
- \( K \): 고려할 이웃의 개수.
- **특징**:
  - \( K \)가 작으면 모델이 복잡해져 과적합 가능성이 높아짐.
  - \( K \)가 크면 모델이 단순해지고, 전체적인 패턴만 반영됨.

### **3.1 이웃 개수 \( n_neighbors \)를 줄이면 왜 \( R^2 \)가 높아지는가?**

- \( K \)가 작아지면, 각 데이터 포인트의 예측 값이 **더 세부적인 패턴**을 반영.
- 결과적으로 훈련 데이터에 더 잘 맞는 모델이 되어 \( R^2 \)가 높아짐.
- 단, **테스트 세트**에서는 과적합으로 인해 성능이 저하될 수 있음.

### **3.2 \( K \)가 커지면 모델이 단순해진다?**

- **모델이 단순해진다**는 의미:
  - 예측 값이 전체 데이터의 **전반적인 경향**만 반영하게 됨.
  - 세부적인 변동이나 패턴을 무시하고, 더 일반화된 예측을 수행.
- 이는 과적합을 방지할 수 있지만, 너무 큰 \( K \)는 중요한 패턴을 놓칠 수 있음.

---

## **4. 훈련 세트와 테스트 세트의 점수 차이**

- 훈련 세트와 테스트 세트의 점수 차이가 크면, **모델이 과적합되었을 가능성**이 높음.
- **이유**:
  - 과적합된 모델은 훈련 데이터에 지나치게 맞춰져 테스트 데이터에 일반화되지 못함.
  - 예: 훈련 세트 \( R^2 = 0.99 \), 테스트 세트 \( R^2 = 0.50 \).

### **4.1 점수 차이가 크면 안 좋은 이유**

- 훈련 데이터에만 특화된 모델은 새로운 데이터에서 성능이 저하됨.
- 머신러닝의 목표는 **일반화 성능**이기 때문에, 테스트 세트 점수가 훈련 세트와 비슷하거나 큰 차이가 없어야 함.

### **4.2 점수 예시 비교**

- **훈련 세트 점수: 50, 테스트 세트 점수: 50**
  - 모델이 훈련 데이터와 테스트 데이터 모두에서 비슷한 성능을 보임.
  - 일반화가 잘 된 모델로 볼 수 있음.
- **훈련 세트 점수: 70, 테스트 세트 점수: 35**
  - 훈련 데이터에서만 잘 작동하고, 테스트 데이터에서는 성능이 크게 저하됨.
  - 과적합 가능성이 높음.

---

## **5. reshape() 메서드**

- **정의**: 배열의 크기를 변경하는 메서드.
- **조건**: 변경 전후 배열의 원소 개수는 같아야 함.
- **사용 목적**:
  - 데이터의 형태를 변환하여 머신러닝 모델에 적합한 입력으로 만듦.
  - 예: 1차원 배열을 2차원 배열로 변경.

---

# 3-2 선형 회귀

## **1. K-최근접 이웃의 한계**

1. **훈련 데이터 범위 밖의 샘플**:
   - 새로운 샘플이 훈련 데이터의 범위를 벗어나면 엉뚱한 값을 예측할 가능성이 큼.
   - 예: 데이터가 훈련된 영역 밖의 값에 대해 예측하려 할 때, KNN은 의미 없는 값을 반환할 수 있음.
2. **거리 계산의 한계**:
   - 데이터 스케일이 조정되지 않으면, 특정 축에 의존적인 거리 계산이 왜곡될 수 있음.
3. **대규모 데이터에 대한 비효율성**:
   - 데이터가 많아질수록 거리 계산 비용이 커지고, 예측 시간이 오래 걸릴 수 있음.

---

## **2. 선형 회귀**

- **정의**: 선형 회귀는 데이터를 직선의 방정식(1차 함수)으로 모델링하는 회귀 분석 방법.
  - 일반적인 직선 방정식: \( y = ax + b \)
  - \( a \): 기울기(계수, 가중치), \( b \): y-절편.
- **주요 클래스**: `LinearRegression` (from scikit-learn).

### **2.1 주요 메서드**

- **`fit(X, y)`**:
  - 훈련 데이터 \((X, y)\)를 사용해 모델을 학습.
- **`score(X, y)`**:
  - 데이터에 대한 \( R^2 \) 결정계수를 계산하여 모델의 성능 평가.
- **`predict(X)`**:
  - 새로운 입력 데이터 \( X \)에 대한 예측 값 반환.

### **2.2 속성**

- **`coef_`**:
  - 선형 회귀 모델에서 각 특성(feature)의 기울기(계수, 가중치).
- **`intercept_`**:
  - y축 절편.

### **2.3 수식과 시각화**

- 직선 방정식:
  \[
  y = coef* \cdot x + intercept*
  \]
- 시각화 예제:
  ![선형 회귀 직선](<3-2_(ax+b).png>)

## **3. 모델 기반 학습**

- **정의**: 데이터를 기반으로 특정 모델(함수)을 학습하여 새로운 데이터에 대해 예측하는 방식.
  - 입력 데이터에서 직접 답을 찾는 **메모리 기반 학습(KNN)**과 대조적.
- **특징**:
  - 데이터의 패턴을 추상화하여 일반화된 수학적 모델(방정식 등)을 생성.
  - 학습 단계와 예측 단계가 분리됨.
  - 모델은 데이터의 본질적인 관계를 표현하려 시도함.
- **장점**:
  - 새로운 데이터에 대해 빠르게 예측 가능.
  - 데이터가 많아져도 예측 속도가 크게 느려지지 않음.
- **단점**:
  - 모델이 복잡한 경우, 학습 단계에서 많은 계산이 필요할 수 있음.
  - 데이터의 특성을 잘못 학습하면 일반화 성능이 낮아질 위험이 있음.

---

## **4. 다항 회귀**

- **정의**: 선형 회귀를 확장하여 데이터에 다항식을 적용하는 회귀 방식.
  - 2차 함수 이상의 다항식 방정식을 사용:
    \[
    y = a_2x^2 + a_1x + a_0
    \]
- **특징**:
  - 선형 회귀로 표현할 수 없는 **비선형 데이터**에도 적합.
  - 입력 데이터를 다항식의 형태로 변환하여 선형 회귀 알고리즘에 적용.

### **4.1 장점**

1. 데이터가 곡선 형태일 때, 선형 회귀보다 더 나은 성능을 발휘함.
2. 복잡한 패턴을 학습할 수 있음.

### **4.2 단점**

1. 다항식의 차수가 높아지면 과적합(Overfitting)의 위험이 있음.
2. 높은 차수를 사용할 경우 계산 비용이 증가함.

### **4.3 다항 회귀와 과적합**

- 차수가 낮으면(단순한 모델): 데이터의 세부적인 패턴을 놓칠 가능성이 있음(과소적합).
- 차수가 높으면(복잡한 모델): 훈련 데이터에는 잘 맞지만, 새로운 데이터에는 성능이 저하될 수 있음(과적합).
- 최적의 다항식 차수를 선택하는 것이 중요함.

# 3-3 특성공학과 규제

복잡한 모델의 과대적합을 막기 위한 릿지와 라쏘 회귀
